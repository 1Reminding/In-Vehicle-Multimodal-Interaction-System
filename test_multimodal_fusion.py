#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€èåˆç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•å„ç§èåˆåœºæ™¯å’Œå†³ç­–ç­–ç•¥ï¼š
1. åˆ†å¿ƒæé†’åœºæ™¯æµ‹è¯•
2. è¯­éŸ³å‘½ä»¤åœºæ™¯æµ‹è¯•
3. æ‰‹åŠ¿æ§åˆ¶åœºæ™¯æµ‹è¯•
4. å†²çªè§£å†³æµ‹è¯•
5. ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
"""

import time
import threading
import unittest
from typing import List, Dict, Any

from modules.fusion import (
    initialize_fusion_system, get_system_status,
    event_bus, state_manager, fusion_engine, scenario_handler,
    ModalityEvent, EventType, ModalityType,
    AudioEvent, VisionEvent, GestureEvent,
    SystemState, InteractionScenario
)


class TestMultimodalFusion(unittest.TestCase):
    """å¤šæ¨¡æ€èåˆç³»ç»Ÿæµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        # é‡ç½®ç³»ç»ŸçŠ¶æ€
        if state_manager.current_session:
            state_manager.end_current_session("test_reset")
        
        # æ¸…ç†äº‹ä»¶å†å²
        event_bus._event_history.clear()
        fusion_engine.interaction_log.clear()
        scenario_handler.response_history.clear()
        
        print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•: {self._testMethodName}")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        if state_manager.current_session:
            state_manager.end_current_session("test_cleanup")
        print(f"âœ… æµ‹è¯•å®Œæˆ: {self._testMethodName}")
    
    def test_distraction_alert_scenario(self):
        """æµ‹è¯•åˆ†å¿ƒæé†’åœºæ™¯"""
        print("   æµ‹è¯•åˆ†å¿ƒæé†’åœºæ™¯...")
        
        # 1. è§¦å‘åˆ†å¿ƒæ£€æµ‹
        gaze_event = VisionEvent(
            event_type=EventType.GAZE_CHANGED,
            data={"state": "left", "timestamp": time.time()},
            confidence=0.9
        )
        event_bus.publish(gaze_event)
        
        # éªŒè¯ä¼šè¯å·²åˆ›å»º
        self.assertIsNotNone(state_manager.current_session)
        self.assertEqual(state_manager.current_session.scenario, InteractionScenario.DISTRACTION_ALERT)
        self.assertEqual(state_manager.current_state, SystemState.WAITING_RESPONSE)
        
        # 2. è¯­éŸ³ç¡®è®¤
        speech_event = AudioEvent(
            event_type=EventType.SPEECH_RECOGNIZED,
            data={"text": "å·²æ³¨æ„é“è·¯"},
            confidence=0.8
        )
        event_bus.publish(speech_event)
        
        intent_event = AudioEvent(
            event_type=EventType.INTENT_CLASSIFIED,
            data={"text": "å·²æ³¨æ„é“è·¯", "intent": "attention_confirm"},
            confidence=0.9
        )
        event_bus.publish(intent_event)
        
        # 3. æ‰‹åŠ¿ç¡®è®¤
        gesture_event = GestureEvent(
            event_type=EventType.GESTURE_DETECTED,
            data={"gesture": "thumbs_up"},
            confidence=0.8
        )
        event_bus.publish(gesture_event)
        
        # ç­‰å¾…èåˆå¤„ç†
        time.sleep(0.1)
        
        # éªŒè¯èåˆç»“æœ
        self.assertEqual(state_manager.current_state, SystemState.IDLE)
        self.assertIsNone(state_manager.current_session)
        self.assertGreater(len(fusion_engine.interaction_log), 0)
        
        # éªŒè¯æœ€åä¸€æ¬¡èåˆå†³ç­–
        last_fusion = fusion_engine.interaction_log[-1]
        self.assertIn(last_fusion["fusion_result"]["decision"], ["confirm", "attention"])
        
        print(f"     âœ“ èåˆå†³ç­–: {last_fusion['fusion_result']['decision']}")
        print(f"     âœ“ ç½®ä¿¡åº¦: {last_fusion['fusion_result']['confidence']:.2f}")
    
    def test_voice_command_scenario(self):
        """æµ‹è¯•è¯­éŸ³å‘½ä»¤åœºæ™¯"""
        print("   æµ‹è¯•è¯­éŸ³å‘½ä»¤åœºæ™¯...")
        
        # è§¦å‘è¯­éŸ³å‘½ä»¤åœºæ™¯
        session_id = scenario_handler.trigger_voice_command_scenario("æ‰“å¼€å¯¼èˆª", 0.9)
        
        # éªŒè¯ä¼šè¯çŠ¶æ€
        self.assertIsNotNone(state_manager.current_session)
        self.assertEqual(state_manager.current_session.scenario, InteractionScenario.VOICE_COMMAND)
        
        # æ·»åŠ ç¡®è®¤æ‰‹åŠ¿
        gesture_event = GestureEvent(
            event_type=EventType.GESTURE_DETECTED,
            data={"gesture": "ok"},
            confidence=0.8
        )
        event_bus.publish(gesture_event)
        
        time.sleep(0.1)
        
        # éªŒè¯ç»“æœ
        self.assertGreater(len(fusion_engine.interaction_log), 0)
        print(f"     âœ“ è¯­éŸ³å‘½ä»¤åœºæ™¯å®Œæˆ")
    
    def test_gesture_control_scenario(self):
        """æµ‹è¯•æ‰‹åŠ¿æ§åˆ¶åœºæ™¯"""
        print("   æµ‹è¯•æ‰‹åŠ¿æ§åˆ¶åœºæ™¯...")
        
        # è§¦å‘æ‰‹åŠ¿æ§åˆ¶åœºæ™¯
        session_id = scenario_handler.trigger_gesture_control_scenario("wave", 0.8)
        
        # éªŒè¯ä¼šè¯çŠ¶æ€
        self.assertIsNotNone(state_manager.current_session)
        self.assertEqual(state_manager.current_session.scenario, InteractionScenario.GESTURE_CONTROL)
        
        # æ·»åŠ è§†çº¿ç¡®è®¤
        gaze_event = VisionEvent(
            event_type=EventType.GAZE_CHANGED,
            data={"state": "center"},
            confidence=0.9
        )
        event_bus.publish(gaze_event)
        
        time.sleep(0.1)
        
        print(f"     âœ“ æ‰‹åŠ¿æ§åˆ¶åœºæ™¯å®Œæˆ")
    
    def test_conflict_resolution(self):
        """æµ‹è¯•å†²çªè§£å†³"""
        print("   æµ‹è¯•å†²çªè§£å†³...")
        
        # åˆ›å»ºåˆ†å¿ƒæé†’ä¼šè¯
        gaze_event = VisionEvent(
            event_type=EventType.GAZE_CHANGED,
            data={"state": "right"},
            confidence=0.9
        )
        event_bus.publish(gaze_event)
        
        # æ·»åŠ å†²çªçš„å“åº”
        # è¯­éŸ³è¯´ç¡®è®¤
        speech_event = AudioEvent(
            event_type=EventType.INTENT_CLASSIFIED,
            data={"intent": "attention_confirm"},
            confidence=0.8
        )
        event_bus.publish(speech_event)
        
        # æ‰‹åŠ¿è¯´æ‹’ç»
        gesture_event = GestureEvent(
            event_type=EventType.GESTURE_DETECTED,
            data={"gesture": "thumbs_down"},
            confidence=0.7
        )
        event_bus.publish(gesture_event)
        
        time.sleep(0.1)
        
        # éªŒè¯å†²çªè§£å†³
        if fusion_engine.interaction_log:
            last_fusion = fusion_engine.interaction_log[-1]
            decision = last_fusion["fusion_result"]["decision"]
            strategy = last_fusion["fusion_result"]["strategy"]
            print(f"     âœ“ å†²çªè§£å†³ç­–ç•¥: {strategy}")
            print(f"     âœ“ æœ€ç»ˆå†³ç­–: {decision}")
    
    def test_timeout_handling(self):
        """æµ‹è¯•è¶…æ—¶å¤„ç†"""
        print("   æµ‹è¯•è¶…æ—¶å¤„ç†...")
        
        # åˆ›å»ºçŸ­è¶…æ—¶çš„ä¼šè¯
        session_id = state_manager.start_interaction(
            scenario=InteractionScenario.DISTRACTION_ALERT,
            expected_modalities=[ModalityType.AUDIO, ModalityType.GESTURE],
            timeout=0.5  # 0.5ç§’è¶…æ—¶
        )
        
        # ç­‰å¾…è¶…æ—¶
        time.sleep(0.6)
        
        # å°è¯•æ·»åŠ äº‹ä»¶ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
        speech_event = AudioEvent(
            event_type=EventType.SPEECH_RECOGNIZED,
            data={"text": "æµ‹è¯•"},
            confidence=0.8
        )
        
        result = state_manager.add_event_to_session(speech_event)
        self.assertFalse(result)  # åº”è¯¥è¿”å›Falseï¼Œå› ä¸ºä¼šè¯å·²è¶…æ—¶
        
        print(f"     âœ“ è¶…æ—¶å¤„ç†æ­£å¸¸")
    
    def test_fusion_strategies(self):
        """æµ‹è¯•ä¸åŒçš„èåˆç­–ç•¥"""
        print("   æµ‹è¯•èåˆç­–ç•¥...")
        
        strategies_tested = []
        
        # æµ‹è¯•ç½®ä¿¡åº¦åŠ æƒç­–ç•¥ï¼ˆè¯­éŸ³å‘½ä»¤åœºæ™¯ï¼‰
        session_id = scenario_handler.trigger_voice_command_scenario("æµ‹è¯•å‘½ä»¤", 0.9)
        gesture_event = GestureEvent(
            event_type=EventType.GESTURE_DETECTED,
            data={"gesture": "ok"},
            confidence=0.6
        )
        event_bus.publish(gesture_event)
        time.sleep(0.1)
        
        if fusion_engine.interaction_log:
            strategy = fusion_engine.interaction_log[-1]["fusion_result"]["strategy"]
            strategies_tested.append(strategy)
        
        # æµ‹è¯•ä¼˜å…ˆçº§ç­–ç•¥ï¼ˆåˆ†å¿ƒæé†’åœºæ™¯ï¼‰
        gaze_event = VisionEvent(
            event_type=EventType.GAZE_CHANGED,
            data={"state": "left"},
            confidence=0.9
        )
        event_bus.publish(gaze_event)
        
        speech_event = AudioEvent(
            event_type=EventType.INTENT_CLASSIFIED,
            data={"intent": "attention_confirm"},
            confidence=0.8
        )
        event_bus.publish(speech_event)
        time.sleep(0.1)
        
        if len(fusion_engine.interaction_log) > 1:
            strategy = fusion_engine.interaction_log[-1]["fusion_result"]["strategy"]
            strategies_tested.append(strategy)
        
        print(f"     âœ“ æµ‹è¯•çš„ç­–ç•¥: {strategies_tested}")
    
    def test_system_performance(self):
        """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½"""
        print("   æµ‹è¯•ç³»ç»Ÿæ€§èƒ½...")
        
        start_time = time.time()
        
        # å¿«é€Ÿå‘é€å¤šä¸ªäº‹ä»¶
        for i in range(10):
            gaze_event = VisionEvent(
                event_type=EventType.GAZE_CHANGED,
                data={"state": "left" if i % 2 == 0 else "center"},
                confidence=0.8
            )
            event_bus.publish(gaze_event)
            
            if i % 3 == 0:  # æ¯3ä¸ªäº‹ä»¶æ·»åŠ ä¸€ä¸ªè¯­éŸ³äº‹ä»¶
                speech_event = AudioEvent(
                    event_type=EventType.SPEECH_RECOGNIZED,
                    data={"text": f"æµ‹è¯•{i}"},
                    confidence=0.7
                )
                event_bus.publish(speech_event)
        
        processing_time = time.time() - start_time
        
        # éªŒè¯æ€§èƒ½
        self.assertLess(processing_time, 1.0)  # åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
        
        print(f"     âœ“ å¤„ç†10ä¸ªäº‹ä»¶ç”¨æ—¶: {processing_time:.3f}ç§’")
        print(f"     âœ“ äº‹ä»¶å†å²å¤§å°: {len(event_bus._event_history)}")


def run_interactive_demo():
    """è¿è¡Œäº¤äº’å¼æ¼”ç¤º"""
    print("ğŸ­ å¤šæ¨¡æ€èåˆç³»ç»Ÿäº¤äº’å¼æ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    initialize_fusion_system()
    
    def print_status():
        status = get_system_status()
        print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€: {status['current_state']}")
        if status['active_session']:
            session = status['active_session']
            print(f"   æ´»è·ƒä¼šè¯: {session['scenario']} ({session['duration']:.1f}s)")
            print(f"   æœŸæœ›æ¨¡æ€: {', '.join(session['expected_modalities'])}")
            print(f"   å·²æ”¶åˆ°æ¨¡æ€: {', '.join(session['received_modalities'])}")
    
    scenarios = [
        ("åˆ†å¿ƒæé†’åœºæ™¯", demo_distraction_scenario),
        ("è¯­éŸ³å‘½ä»¤åœºæ™¯", demo_voice_command_scenario),
        ("æ‰‹åŠ¿æ§åˆ¶åœºæ™¯", demo_gesture_control_scenario),
        ("å†²çªè§£å†³æ¼”ç¤º", demo_conflict_resolution)
    ]
    
    for name, demo_func in scenarios:
        print(f"\nğŸ¯ æ¼”ç¤º: {name}")
        print("-" * 30)
        demo_func()
        print_status()
        time.sleep(1)
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
    status = get_system_status()
    print(f"   ä¼šè¯ç»Ÿè®¡: {status['session_stats']}")
    print(f"   èåˆç»Ÿè®¡: {status['fusion_stats']}")
    print(f"   å“åº”ç»Ÿè®¡: {status['response_stats']}")


def demo_distraction_scenario():
    """æ¼”ç¤ºåˆ†å¿ƒæé†’åœºæ™¯"""
    # 1. è§†çº¿åç¦»
    gaze_event = VisionEvent(
        event_type=EventType.GAZE_CHANGED,
        data={"state": "left"},
        confidence=0.9
    )
    event_bus.publish(gaze_event)
    print("   1. è§†çº¿åç¦» -> è§¦å‘åˆ†å¿ƒæ£€æµ‹")
    time.sleep(1)
    
    # 2. è¯­éŸ³ç¡®è®¤
    intent_event = AudioEvent(
        event_type=EventType.INTENT_CLASSIFIED,
        data={"intent": "attention_confirm"},
        confidence=0.8
    )
    event_bus.publish(intent_event)
    print("   2. è¯­éŸ³ç¡®è®¤ -> èåˆå¤„ç†")
    time.sleep(1)
    
    # 3. æ‰‹åŠ¿ç¡®è®¤
    gesture_event = GestureEvent(
        event_type=EventType.GESTURE_DETECTED,
        data={"gesture": "thumbs_up"},
        confidence=0.8
    )
    event_bus.publish(gesture_event)
    print("   3. æ‰‹åŠ¿ç¡®è®¤ -> å®Œæˆäº¤äº’")
    time.sleep(0.5)


def demo_voice_command_scenario():
    """æ¼”ç¤ºè¯­éŸ³å‘½ä»¤åœºæ™¯"""
    session_id = scenario_handler.trigger_voice_command_scenario("æ‰“å¼€éŸ³ä¹", 0.9)
    print("   1. è¯­éŸ³å‘½ä»¤: 'æ‰“å¼€éŸ³ä¹'")
    time.sleep(1)
    
    gesture_event = GestureEvent(
        event_type=EventType.GESTURE_DETECTED,
        data={"gesture": "ok"},
        confidence=0.8
    )
    event_bus.publish(gesture_event)
    print("   2. æ‰‹åŠ¿ç¡®è®¤: OK")
    time.sleep(0.5)


def demo_gesture_control_scenario():
    """æ¼”ç¤ºæ‰‹åŠ¿æ§åˆ¶åœºæ™¯"""
    session_id = scenario_handler.trigger_gesture_control_scenario("wave", 0.8)
    print("   1. æ‰‹åŠ¿æ§åˆ¶: æŒ¥æ‰‹")
    time.sleep(1)
    
    gaze_event = VisionEvent(
        event_type=EventType.GAZE_CHANGED,
        data={"state": "center"},
        confidence=0.9
    )
    event_bus.publish(gaze_event)
    print("   2. è§†çº¿ç¡®è®¤: ä¸­å¿ƒ")
    time.sleep(0.5)


def demo_conflict_resolution():
    """æ¼”ç¤ºå†²çªè§£å†³"""
    # è§¦å‘åˆ†å¿ƒæ£€æµ‹
    gaze_event = VisionEvent(
        event_type=EventType.GAZE_CHANGED,
        data={"state": "right"},
        confidence=0.9
    )
    event_bus.publish(gaze_event)
    print("   1. è§†çº¿åç¦» -> åˆ†å¿ƒæ£€æµ‹")
    time.sleep(1)
    
    # å†²çªçš„å“åº”
    speech_event = AudioEvent(
        event_type=EventType.INTENT_CLASSIFIED,
        data={"intent": "attention_confirm"},
        confidence=0.8
    )
    event_bus.publish(speech_event)
    print("   2. è¯­éŸ³ç¡®è®¤: å·²æ³¨æ„")
    
    gesture_event = GestureEvent(
        event_type=EventType.GESTURE_DETECTED,
        data={"gesture": "thumbs_down"},
        confidence=0.7
    )
    event_bus.publish(gesture_event)
    print("   3. æ‰‹åŠ¿æ‹’ç»: æ‹‡æŒ‡å‘ä¸‹")
    print("   4. å†²çªè§£å†³: åŸºäºä¼˜å…ˆçº§é€‰æ‹©è¯­éŸ³")
    time.sleep(0.5)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--demo":
        run_interactive_demo()
    else:
        # è¿è¡Œå•å…ƒæµ‹è¯•
        print("ğŸ§ª è¿è¡Œå¤šæ¨¡æ€èåˆç³»ç»Ÿæµ‹è¯•")
        unittest.main(verbosity=2) 