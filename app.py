#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½¦è½½å¤šæ¨¡æ€æ™ºèƒ½äº¤äº’ç³»ç»Ÿ - AIå¢å¼ºç‰ˆ

é›†æˆDeepSeek APIè¿›è¡Œæ™ºèƒ½å¤šæ¨¡æ€èåˆå’Œè¯­éŸ³åé¦ˆ
é›†æˆäº¤äº’æ—¥å¿—è®°å½•å’ŒåŸºç¡€ç”¨æˆ·é…ç½®åŠŸèƒ½
"""

import time
import cv2
import threading
import signal
import sys
import json
from typing import Dict, Any

# å¯¼å…¥ç°æœ‰æ¨¡å—
from modules.audio.recorder import Recorder
from modules.audio.speech_recognizer import transcribe
from modules.vision.gesture.gesture_recognizer import GestureRecognizer
from modules.vision.head.head_pose_detector import HeadPoseDetector
from modules.vision.gaze.gaze_tracking import GazeTracking
from modules.vision.camera_manager import get_camera_manager, release_camera_manager
from modules.actions.action_handler import handle_action

# å¯¼å…¥AIæ¨¡å—
from modules.ai.deepseek_client import deepseek_client, MultimodalInput, AIResponse
from modules.ai.multimodal_collector import multimodal_collector

# å¯¼å…¥ç³»ç»Ÿç®¡ç†æ¨¡å—ï¼ˆä»…ç”¨äºäº¤äº’æ—¥å¿—ï¼‰
from modules.system.system_manager import system_manager

import os
import requests
from PyQt5.QtGui     import QGuiApplication
from PyQt5.QtQml     import QQmlApplicationEngine
from PyQt5.QtCore   import QUrl, QObject, pyqtSignal, pyqtSlot, QTimer


class UIBackend(QObject):
    """æš´éœ²ç»™ QML çš„æ¡¥æ¥å¯¹è±¡"""
    commandIssued = pyqtSignal(str)
    weatherUpdated = pyqtSignal(str)
    
    # ç³»ç»ŸçŠ¶æ€ä¿¡å·
    userStatusUpdated = pyqtSignal(str)  # ç”¨æˆ·çŠ¶æ€æ›´æ–°
    systemAlert = pyqtSignal(str)        # ç³»ç»Ÿè­¦å‘Š

    @pyqtSlot(str)
    def requestAction(self, cmd):
        print(f"ğŸ”· å‰ç«¯è¯·æ±‚åŠ¨ä½œï¼š{cmd}")
        handle_action(cmd)
    
    @pyqtSlot(str)
    def setCurrentUser(self, user_id):
        """è®¾ç½®å½“å‰ç”¨æˆ·ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        print(f"ğŸ‘¤ åˆ‡æ¢ç”¨æˆ·ï¼š{user_id}")
        if system_manager.user_config.load_user(user_id):
            system_manager.start_session(user_id)
            self.userStatusUpdated.emit(f"ç”¨æˆ· {user_id} å·²ç™»å½•")
        else:
            self.userStatusUpdated.emit(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨")

# ä½¿ç”¨åŸºæœ¬çš„UIåç«¯
ui_backend = UIBackend()

class AIMultimodalApp:
    """AIå¢å¼ºçš„å¤šæ¨¡æ€äº¤äº’åº”ç”¨"""
    
    def __init__(self):
        self.running = False
        self.audio_thread = None
        self.vision_thread = None
        
        # å½“å‰ç”¨æˆ·ä¿¡æ¯ï¼ˆç®€åŒ–ï¼‰
        self.current_user_id = None
        
        self.stats = {
            "ai_requests": 0,
            "successful_responses": 0,
            "speech_inputs": 0,
            "gesture_detections": 0,
            "gaze_changes": 0,
            "start_time": time.time()
        }
        
        # è®¾ç½®å¤šæ¨¡æ€æ•°æ®å›è°ƒ
        multimodal_collector.set_callback(self.on_multimodal_data_ready)
        
        # åˆå§‹åŒ–ç³»ç»Ÿç®¡ç†ï¼ˆä»…ç”¨äºäº¤äº’æ—¥å¿—ï¼‰
        self._initialize_system_management()
        
        print("ğŸš€ AIå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("ğŸ“‹ åŠŸèƒ½è¯´æ˜:")
        print("   - çœ¼åŠ¨åç¦»è¶…è¿‡3ç§’è§¦å‘AIåˆ†æ")
        print("   - è¯­éŸ³è¾“å…¥ç«‹å³è§¦å‘AIåˆ†æ")
        print("   - æ‰‹åŠ¿è¯†åˆ«è§¦å‘AIåˆ†æ")
        print("   - AIåˆ†æç»“æœé€šè¿‡æ–‡æœ¬æ˜¾ç¤º")
        print("   - è‡ªåŠ¨è®°å½•æ‰€æœ‰äº¤äº’æ—¥å¿—ç”¨äºåˆ†æä¼˜åŒ–")
        print("   - æŒ‰ Ctrl+C é€€å‡ºç³»ç»Ÿ")
    
    def _initialize_system_management(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç®¡ç†åŠŸèƒ½ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸»è¦ç”¨äºäº¤äº’æ—¥å¿—ï¼‰"""
        try:
            # è®¾ç½®é»˜è®¤ç”¨æˆ·ï¼ˆå¦‚æœæ²¡æœ‰ç”¨æˆ·åˆ™åˆ›å»ºé»˜è®¤ç”¨æˆ·ï¼‰
            default_user_id = "default_user"
            if not system_manager.user_config.load_user(default_user_id):
                print(f"ğŸ“‹ åˆ›å»ºé»˜è®¤ç”¨æˆ·ï¼š{default_user_id}")
                system_manager.create_user_profile(default_user_id, "é»˜è®¤ç”¨æˆ·", "driver")
            
            # åŠ è½½é»˜è®¤ç”¨æˆ·å¹¶å¼€å§‹ä¼šè¯
            if system_manager.user_config.load_user(default_user_id):
                self.current_user_id = default_user_id
                system_manager.start_session(default_user_id)
                print(f"âœ… ç³»ç»Ÿç®¡ç†åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰ç”¨æˆ·ï¼š{default_user_id}")
            else:
                print("âš ï¸ æ— æ³•åŠ è½½é»˜è®¤ç”¨æˆ·ï¼Œç³»ç»Ÿå°†ä»¥è®¿å®¢æ¨¡å¼è¿è¡Œ")
                
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿç®¡ç†åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            print("âš ï¸ ç³»ç»Ÿå°†ä»¥åŸºç¡€æ¨¡å¼è¿è¡Œï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")
    
    def _get_simple_user_settings(self) -> Dict[str, Any]:
        """è·å–ç®€åŒ–çš„ç”¨æˆ·è®¾ç½®ï¼ˆä¸»è¦ç”¨äºäº¤äº’æ—¥å¿—è®°å½•ï¼‰"""
        if not self.current_user_id:
            return {}
        
        try:
            # è·å–åŸºç¡€ç”¨æˆ·ç»Ÿè®¡
            user_stats = system_manager.user_config.get_interaction_stats()
            
            return {
                "user_id": self.current_user_id,
                "interaction_stats": user_stats,
                "most_used_gesture": user_stats.get("most_used_gesture"),
                "most_used_voice_command": user_stats.get("most_used_voice_command")
            }
        except Exception as e:
            print(f"âš ï¸ è·å–ç”¨æˆ·è®¾ç½®å¤±è´¥ï¼š{e}")
            return {"user_id": self.current_user_id}

    def on_multimodal_data_ready(self, multimodal_input: MultimodalInput):
        """å¤„ç†å¤šæ¨¡æ€æ•°æ®å°±ç»ªäº‹ä»¶"""
        print(f"\nğŸ¤– AIåˆ†æå¼€å§‹...")
        print(f"ğŸ“Š è¾“å…¥æ•°æ®:")
        print(f"   ğŸ‘ çœ¼åŠ¨: {multimodal_input.gaze_data['state']} ({multimodal_input.gaze_data['duration']:.1f}s)")
        print(f"   ğŸ– æ‰‹åŠ¿: {multimodal_input.gesture_data['gesture']} ({multimodal_input.gesture_data['confidence']:.2f})")
        print(f"   ğŸ¤ è¯­éŸ³: '{multimodal_input.speech_data['text']}'")
        
        # ç¡®å®šäº¤äº’ç±»åˆ«
        interaction_category = self._get_interaction_category(multimodal_input)
        
        # è·å–ç”¨æˆ·è®¾ç½®
        user_settings = self._get_simple_user_settings()
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["ai_requests"] += 1
        start_time = time.time()
        
        try:
            # è°ƒç”¨DeepSeek APIè¿›è¡Œåˆ†æ
            ai_response = deepseek_client.analyze_multimodal_data(multimodal_input)
            processing_time = time.time() - start_time
            
            print(f"\nğŸ§  AIåˆ†æç»“æœ:")
            print(f"   ğŸ“‹ æ¨èæ“ä½œ: {ai_response.recommendation_text}")
            print(f"   ğŸ¯ ç½®ä¿¡åº¦: {ai_response.confidence:.2f}")
            print(f"   ğŸ’­ æ¨ç†è¿‡ç¨‹: {ai_response.reasoning}")
            
            # è§£ææ“ä½œæŒ‡ä»¤
            try:
                action_data = json.loads(ai_response.action_code)
                print(f"   âš™ï¸ æ“ä½œæŒ‡ä»¤: {action_data}")
            except json.JSONDecodeError:
                print(f"   âš™ï¸ æ“ä½œæŒ‡ä»¤: {ai_response.action_code}")
            
            # è®°å½•äº¤äº’æ—¥å¿—
            interaction_data = {
                "modality": "multimodal",
                "type": "ai_analysis",
                "category": interaction_category,
                "gaze_data": multimodal_input.gaze_data,
                "gesture_data": multimodal_input.gesture_data,
                "speech_data": multimodal_input.speech_data,
                "user_id": self.current_user_id,
                "user_settings": user_settings
            }
            
            ai_response_data = {
                "confidence": ai_response.confidence,
                "recommendation": ai_response.recommendation_text,
                "reasoning": ai_response.reasoning,
                "action_code": ai_response.action_code
            }
            
            # é€šè¿‡ç³»ç»Ÿç®¡ç†å™¨è®°å½•äº¤äº’æ—¥å¿—
            system_result = system_manager.process_multimodal_interaction(
                interaction_data=interaction_data,
                ai_response=ai_response_data,
                processing_time=processing_time,
                success=True
            )
            
            if system_result["success"]:
                print(f"âœ… äº¤äº’æ—¥å¿—è®°å½•æˆåŠŸ - ä¼šè¯ID: {system_result.get('session_id')}")
                
                # è§£ææ“ä½œæŒ‡ä»¤å¹¶æ‰§è¡Œ
                try:
                    action_data = json.loads(ai_response.action_code)
                    print(f"   âš™ï¸ æ‰§è¡Œæ“ä½œ: {action_data}")
                    handle_action(action_data)
                    ui_backend.commandIssued.emit(json.dumps(action_data))

                except json.JSONDecodeError:
                    print(f"   âš™ï¸ æ‰§è¡Œæ“ä½œ: {ai_response.action_code}")       
                    handle_action(ai_response.action_code)
                    ui_backend.commandIssued.emit(ai_response.action_code)
                
                # æ–‡æœ¬åé¦ˆ
                if ai_response.recommendation_text:
                    print(f"ğŸ’¬ ç³»ç»Ÿå»ºè®®: {ai_response.recommendation_text}")
                
                # æ·»åŠ åˆ°å¯¹è¯å†å²
                deepseek_client.add_to_conversation_history(multimodal_input, ai_response)
                
                self.stats["successful_responses"] += 1
            else:
                print(f"ğŸš« äº¤äº’æ—¥å¿—è®°å½•å¤±è´¥: {system_result['message']}")
            
        except Exception as e:
            processing_time = time.time() - start_time
            print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
            print("ğŸ’¬ ç³»ç»Ÿæç¤º: æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚")
            
            # è®°å½•é”™è¯¯åˆ°äº¤äº’æ—¥å¿—
            interaction_data = {
                "modality": "multimodal",
                "type": "ai_analysis_error",
                "category": interaction_category,
                "error": str(e),
                "user_id": self.current_user_id
            }
            
            system_manager.process_multimodal_interaction(
                interaction_data=interaction_data,
                processing_time=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _get_interaction_category(self, multimodal_input: MultimodalInput) -> str:
        """æ ¹æ®å¤šæ¨¡æ€è¾“å…¥æ¨æ–­äº¤äº’ç±»åˆ«"""
        text = multimodal_input.speech_data.get('text', '').lower()
        
        if any(word in text for word in ['å¯¼èˆª', 'ç›®çš„åœ°', 'è·¯çº¿', 'åœ°å›¾']):
            return 'navigation'
        elif any(word in text for word in ['éŸ³ä¹', 'æ­Œæ›²', 'æ’­æ”¾', 'æš‚åœ']):
            return 'music'
        elif any(word in text for word in ['æ¸©åº¦', 'ç©ºè°ƒ', 'æš–æ°”', 'åˆ¶å†·']):
            return 'climate'
        elif any(word in text for word in ['ç”µè¯', 'é€šè¯', 'è”ç³»', 'çŸ­ä¿¡']):
            return 'communication'
        elif any(word in text for word in ['è®¾ç½®', 'é…ç½®', 'åå¥½']):
            return 'settings'
        else:
            return 'system'
    
    def switch_user(self, user_id: str) -> bool:
        """åˆ‡æ¢ç”¨æˆ·ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # ç»“æŸå½“å‰ä¼šè¯
            if self.current_user_id:
                system_manager.end_session()
            
            # åŠ è½½æ–°ç”¨æˆ·
            if system_manager.user_config.load_user(user_id):
                self.current_user_id = user_id
                
                # å¼€å§‹æ–°ä¼šè¯
                system_manager.start_session(user_id)
                
                print(f"âœ… ç”¨æˆ·åˆ‡æ¢æˆåŠŸï¼š{user_id}")
                ui_backend.userStatusUpdated.emit(f"å½“å‰ç”¨æˆ·ï¼š{user_id}")
                
                return True
            else:
                print(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨ï¼š{user_id}")
                ui_backend.userStatusUpdated.emit(f"ç”¨æˆ· {user_id} ä¸å­˜åœ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ç”¨æˆ·åˆ‡æ¢å¤±è´¥ï¼š{e}")
            ui_backend.userStatusUpdated.emit(f"ç”¨æˆ·åˆ‡æ¢å¤±è´¥ï¼š{e}")
            return False
    
    def audio_worker(self):
        """éŸ³é¢‘å·¥ä½œçº¿ç¨‹"""
        print("ğŸ¤ éŸ³é¢‘çº¿ç¨‹å¯åŠ¨")
        rec = Recorder()
        
        try:
            for seg in rec.record_stream():
                if not self.running:
                    break
                
                # è¯­éŸ³è¯†åˆ«
                text = transcribe(seg["wav"])
                if not text or not text.strip():
                    continue
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats["speech_inputs"] += 1
                
                print(f"ğŸ¤ è¯­éŸ³è¯†åˆ«: '{text}'")
                
                # æ›´æ–°å¤šæ¨¡æ€æ”¶é›†å™¨
                speech_data = {
                    "text": text,
                }
                multimodal_collector.update_speech_data(speech_data)
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            print("ğŸ¤ éŸ³é¢‘çº¿ç¨‹ç»“æŸ")
    
    def vision_worker(self):
        """è§†è§‰å·¥ä½œçº¿ç¨‹"""
        print("ğŸ‘ è§†è§‰çº¿ç¨‹å¯åŠ¨")
        
        # è·å–æ‘„åƒå¤´ç®¡ç†å™¨
        camera_manager = get_camera_manager()
        
        # åˆå§‹åŒ–è§†è§‰æ¨¡å—
        gr = GestureRecognizer()
        hp = HeadPoseDetector()
        gaze = GazeTracking()
        
        if not camera_manager.is_opened:
            print("âŒ æ‘„åƒå¤´æ— æ³•æ‰“å¼€")
            return
        
        # çŠ¶æ€å˜é‡
        last_gesture = None
        last_gaze_state = None
        stable_gesture = None
        stable_start_time = None
        stability_threshold = 0.5
        
        try:
            while self.running:
                ok, frame = camera_manager.read_frame()
                if not ok:
                    time.sleep(0.01)
                    continue
                
                frame = cv2.flip(frame, 1)
                
                # çœ¼åŠ¨è¿½è¸ª
                gaze.refresh(frame)
                current_gaze_state = "center"
                if gaze.is_right():
                    current_gaze_state = "right"
                elif gaze.is_left():
                    current_gaze_state = "left"
                elif gaze.is_center():
                    current_gaze_state = "center"
                
                # çœ¼åŠ¨çŠ¶æ€å˜åŒ–æ—¶æ›´æ–°æ”¶é›†å™¨
                if current_gaze_state != last_gaze_state:
                    last_gaze_state = current_gaze_state
                    self.stats["gaze_changes"] += 1
                    
                    gaze_data = {
                        "state": current_gaze_state,
                        "ts": time.time()
                    }
                    multimodal_collector.update_gaze_data(gaze_data)
                
                # å¤´éƒ¨å§¿æ€æ£€æµ‹
                head_pose_result = hp.process_frame(frame)
                if head_pose_result:
                    if head_pose_result["type"] == "head_pose_calibrated":
                        print(f"ğŸ¯ å¤´éƒ¨å§¿æ€åŸºçº¿æ ¡å‡†: pitch0={head_pose_result['pitch0']:.1f}Â°")
                    elif head_pose_result["type"] == "head_pose":
                        print(f"ğŸ—£ å¤´éƒ¨å§¿æ€: {head_pose_result}")
                
                # æ‰‹åŠ¿è¯†åˆ«
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                rgb.flags.writeable = False
                res = gr.hands.process(rgb)
                rgb.flags.writeable = True
                
                current_time = time.time()
                current_gesture = None
                current_conf = 0.0
                
                if res.multi_hand_landmarks:
                    for hlm in res.multi_hand_landmarks:
                        gesture, conf = gr._recognize_gesture(hlm)
                        if gesture:
                            current_gesture = gesture
                            current_conf = conf
                            break
                
                # æ‰‹åŠ¿ç¨³å®šæ€§æ£€æµ‹
                if current_gesture == stable_gesture:
                    if stable_start_time is not None:
                        stable_duration = current_time - stable_start_time
                        if stable_duration >= stability_threshold and current_gesture != last_gesture:
                            last_gesture = current_gesture
                            self.stats["gesture_detections"] += 1
                            
                            gesture_data = {
                                "gesture": current_gesture,
                                "conf": current_conf,
                                "ts": current_time,
                                "stable_duration": stable_duration
                            }
                            
                            print(f"ğŸ– æ‰‹åŠ¿æ£€æµ‹: {current_gesture} (ç½®ä¿¡åº¦: {current_conf:.2f})")
                            multimodal_collector.update_gesture_data(gesture_data)
                else:
                    stable_gesture = current_gesture
                    stable_start_time = current_time if current_gesture else None
                
        except Exception as e:
            print(f"âŒ è§†è§‰çº¿ç¨‹é”™è¯¯: {e}")
        finally:
            gr.hands.close()
            print("ğŸ‘ è§†è§‰çº¿ç¨‹ç»“æŸ")
    
    def print_status(self):
        """æ‰“å°ç³»ç»ŸçŠ¶æ€"""
        runtime = time.time() - self.stats["start_time"]
        
        print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€ (è¿è¡Œæ—¶é—´: {runtime:.1f}ç§’)")
        print(f"   ğŸ¤– AIè¯·æ±‚æ¬¡æ•°: {self.stats['ai_requests']}")
        print(f"   âœ… æˆåŠŸå“åº”: {self.stats['successful_responses']}")
        print(f"   ğŸ¤ è¯­éŸ³è¾“å…¥: {self.stats['speech_inputs']}")
        print(f"   ğŸ– æ‰‹åŠ¿æ£€æµ‹: {self.stats['gesture_detections']}")
        print(f"   ğŸ‘ çœ¼åŠ¨å˜åŒ–: {self.stats['gaze_changes']}")
        
        # å¤šæ¨¡æ€æ”¶é›†å™¨çŠ¶æ€
        collector_status = multimodal_collector.get_status()
        print(f"   ğŸ“‹ æ”¶é›†å™¨çŠ¶æ€: {'æ”¶é›†ä¸­' if collector_status['is_collecting'] else 'å¾…æœº'}")
        
        # ç³»ç»Ÿç®¡ç†çŠ¶æ€
        if self.current_user_id:
            print(f"   ğŸ‘¤ å½“å‰ç”¨æˆ·: {self.current_user_id}")
            
            # è·å–äº¤äº’æ—¥å¿—ç»Ÿè®¡
            try:
                system_analytics = system_manager.get_system_analytics(days=1)
                print(f"   ğŸ“ˆ ä»Šæ—¥äº¤äº’: {system_analytics.get('total_interactions', 0)} æ¬¡")
                print(f"   ğŸ“Š æˆåŠŸç‡: {system_analytics.get('success_rate', 0):.1%}")
                
            except Exception as e:
                print(f"   âš ï¸ ç³»ç»Ÿç»Ÿè®¡è·å–å¤±è´¥: {e}")
        else:
            print(f"   ğŸ‘¤ å½“å‰ç”¨æˆ·: æœªç™»å½•")
    
    def get_system_dashboard(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ§åˆ¶é¢æ¿ä¿¡æ¯"""
        try:
            if not self.current_user_id:
                return {
                    "user_info": {"status": "æœªç™»å½•"},
                    "system_status": {"message": "è¯·å…ˆç™»å½•ç”¨æˆ·"},
                    "stats": self.stats
                }
            
            # è·å–ç³»ç»Ÿç®¡ç†å™¨çš„æ§åˆ¶é¢æ¿
            dashboard = system_manager.get_user_dashboard()
            
            # æ·»åŠ åº”ç”¨å±‚ç»Ÿè®¡
            dashboard["app_stats"] = self.stats
            dashboard["runtime"] = time.time() - self.stats["start_time"]
            
            return dashboard
            
        except Exception as e:
            print(f"âš ï¸ è·å–ç³»ç»Ÿæ§åˆ¶é¢æ¿å¤±è´¥: {e}")
            return {
                "error": str(e),
                "stats": self.stats
            }
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        print(f"\nğŸ›‘ æ¥æ”¶åˆ°é€€å‡ºä¿¡å· ({signum})")
        self.stop()
    
    def start(self):
        """å¯åŠ¨åº”ç”¨"""
        print("ğŸš€ å¯åŠ¨AIå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿ...")
        
        self.running = True
        
        # å¯åŠ¨éŸ³é¢‘çº¿ç¨‹
        self.audio_thread = threading.Thread(target=self.audio_worker, daemon=True)
        self.audio_thread.start()
        
        # å¯åŠ¨è§†è§‰çº¿ç¨‹ï¼ˆä¸»çº¿ç¨‹ï¼‰
        try:
            self.vision_worker()
        except KeyboardInterrupt:
            print("\nâŒ¨ï¸ ç”¨æˆ·ä¸­æ–­")
        finally:
            self.stop()
    
    def stop(self):
        """åœæ­¢åº”ç”¨"""
        if not self.running:
            return
        
        print("ğŸ›‘ æ­£åœ¨åœæ­¢AIå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿ...")
        self.running = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.audio_thread and self.audio_thread.is_alive():
            self.audio_thread.join(timeout=2.0)
        
        # ç»“æŸç³»ç»Ÿç®¡ç†ä¼šè¯
        try:
            if self.current_user_id:
                system_manager.end_session()
                print(f"ğŸ“‹ ç”¨æˆ·ä¼šè¯å·²ç»“æŸ: {self.current_user_id}")
        except Exception as e:
            print(f"âš ï¸ ç»“æŸä¼šè¯æ—¶å‡ºé”™: {e}")
        
        # æ‰“å°æœ€ç»ˆçŠ¶æ€å’Œç³»ç»Ÿåˆ†æ
        self.print_status()
        
        # æ˜¾ç¤ºäº¤äº’æ—¥å¿—æ€»ç»“
        try:
            print(f"\nğŸ“ˆ äº¤äº’æ—¥å¿—æ€»ç»“:")
            analytics = system_manager.get_system_analytics(days=1)
            print(f"   ğŸ“Š ä»Šæ—¥æ€»äº¤äº’: {analytics.get('total_interactions', 0)} æ¬¡")
            print(f"   âœ… æˆåŠŸç‡: {analytics.get('success_rate', 0):.1%}")
            print(f"   â±ï¸ å¹³å‡å“åº”æ—¶é—´: {analytics.get('avg_response_time', 0):.2f}ç§’")
            
            # ç”¨æˆ·äº¤äº’ä¹ æƒ¯åˆ†æ
            if self.current_user_id:
                user_stats = system_manager.user_config.get_interaction_stats()
                print(f"   ğŸ– æœ€å¸¸ç”¨æ‰‹åŠ¿: {user_stats.get('most_used_gesture', 'none')}")
                print(f"   ğŸ¤ æœ€å¸¸ç”¨è¯­éŸ³æŒ‡ä»¤: {user_stats.get('most_used_voice_command', 'none')}")
                
        except Exception as e:
            print(f"âš ï¸ äº¤äº’æ—¥å¿—æ€»ç»“è·å–å¤±è´¥: {e}")
        
        # å…³é—­èµ„æº
        release_camera_manager()
        
        print("âœ… AIå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿå·²åœæ­¢")


# å…¨å±€åº”ç”¨å®ä¾‹ï¼Œç”¨äºUIäº¤äº’
app_instance = None

def get_app_instance():
    """è·å–åº”ç”¨å®ä¾‹"""
    global app_instance
    return app_instance

# ä¸ºUIæä¾›çš„ç³»ç»Ÿç®¡ç†æ¥å£ï¼ˆç®€åŒ–ç‰ˆï¼‰
class SystemManagementAPI:
    """ç³»ç»Ÿç®¡ç†APIï¼Œä¾›UIè°ƒç”¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸»è¦ç”¨äºäº¤äº’æ—¥å¿—ï¼‰"""
    
    @staticmethod
    def get_current_user():
        """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
        app = get_app_instance()
        if app and app.current_user_id:
            try:
                user_name = system_manager.user_config.get_preference('user_info.name', 'æœªçŸ¥')
                last_login = system_manager.user_config.get_preference('user_info.last_login', 'æœªçŸ¥')
                
                return {
                    "user_id": app.current_user_id,
                    "name": user_name,
                    "last_login": last_login
                }
            except:
                return None
        return None
    
    @staticmethod
    def get_system_status():
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        app = get_app_instance()
        if app:
            return app.get_system_dashboard()
        return {"error": "åº”ç”¨æœªåˆå§‹åŒ–"}
    
    @staticmethod
    def switch_user(user_id: str):
        """åˆ‡æ¢ç”¨æˆ·"""
        app = get_app_instance()
        if app:
            return app.switch_user(user_id)
        return False
    
    @staticmethod
    def get_interaction_stats(days: int = 7):
        """è·å–äº¤äº’ç»Ÿè®¡"""
        try:
            return system_manager.logger.get_interaction_stats(days=days)
        except Exception as e:
            return {"error": str(e)}

def fetch_weather(city="Tianjin"):
    #api_key = "e8527d822a260a90258bbbcf110506e8"
    url = f"http://api.openweathermap.org/data/2.5/weather?q=Tianjin&appid=e8527d822a260a90258bbbcf110506e8&units=metric&lang=zh_cn"

    try:
        res = requests.get(url, timeout=5)
        data = res.json()
        if res.status_code == 200:
            temp = data['main']['temp']
            desc = data['weather'][0]['description']
            return f"{round(temp)}Â°C {desc}"
        else:
            print("âŒ å¤©æ°” API å“åº”å¤±è´¥ï¼š", data)
            return "å¤©æ°”åŠ è½½å¤±è´¥"
    except Exception as e:
        print("âŒ è¯·æ±‚å¤©æ°”å¤±è´¥ï¼š", e)
        return "å¤©æ°”å¼‚å¸¸"

def main():
    """ä¸»å‡½æ•°"""
    global app_instance
    
    print("=" * 60)
    print("ğŸš— è½¦è½½å¤šæ¨¡æ€æ™ºèƒ½äº¤äº’ç³»ç»Ÿ - AIå¢å¼ºç‰ˆ")
    print("ğŸ”§ é›†æˆäº¤äº’æ—¥å¿—è®°å½•å’ŒåŸºç¡€ç”¨æˆ·é…ç½®åŠŸèƒ½")
    print("=" * 60)
    
    # 1. å¯åŠ¨åç«¯å¤šæ¨¡æ€æœåŠ¡ï¼ˆåœ¨åå°çº¿ç¨‹ï¼‰
    backend = AIMultimodalApp()
    app_instance = backend  # è®¾ç½®å…¨å±€å®ä¾‹
    
    signal.signal(signal.SIGINT, backend.signal_handler)
    signal.signal(signal.SIGTERM, backend.signal_handler)

    threading.Thread(target=backend.start, daemon=True).start()

    # 2. å¯åŠ¨ QML ç•Œé¢
    app = QGuiApplication(sys.argv)
    engine = QQmlApplicationEngine()
    
    # æ³¨å†Œç³»ç»Ÿç®¡ç†APIåˆ°QMLä¸Šä¸‹æ–‡
    engine.rootContext().setContextProperty("UIBackend", ui_backend)
    engine.rootContext().setContextProperty("SystemAPI", SystemManagementAPI)

    qml_path = os.path.join(os.path.dirname(__file__), "ui", "Main.qml")
    engine.load(QUrl.fromLocalFile(qml_path))
    if not engine.rootObjects():
        print("âŒ æ— æ³•åŠ è½½ QML ç•Œé¢ï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–è¯­æ³•")
        return 1

    # 3. åˆå§‹åŒ–ç•Œé¢æ•°æ®
    weather_text = fetch_weather("Tianjin")
    QTimer.singleShot(10, lambda: ui_backend.weatherUpdated.emit(weather_text))
    
    print("ğŸ›ï¸ äº¤äº’æ—¥å¿—è®°å½•åŠŸèƒ½å·²é›†æˆåˆ°åº”ç”¨")

    # 4. è¿›å…¥ Qt äº‹ä»¶å¾ªç¯ï¼ˆé˜»å¡ï¼‰
    try:
        return app.exec_()
    except KeyboardInterrupt:
        print("\nâŒ¨ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
        backend.stop()
        return 0
    finally:
        # ç¡®ä¿æ¸…ç†èµ„æº
        if app_instance:
            app_instance.stop()


if __name__ == "__main__":
    main() 